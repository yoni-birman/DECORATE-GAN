{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib .pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "dtype: int64\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "dtype: int64\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "dtype: int64\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "dtype: int64\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "dtype: int64\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "dtype: int64\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "dtype: int64\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "dtype: int64\n",
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "5    1\n",
      "6    1\n",
      "7    1\n",
      "8    1\n",
      "9    1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Main\n",
    "i = 1\n",
    "trials = 1\n",
    "data = extract_features()\n",
    "ensamble_list = []\n",
    "ensamble_list.append(create_classifier(data))\n",
    "ensemble_error = compute_ensemble_error(data,ensamble_list) # Firts enbamble error\n",
    "r_size = 10 # Number of instances of training data to generate\n",
    "c_size = 5 # Number of classifiers in the ensamble\n",
    "i_max = 10 # Number of iterations\n",
    "while i < c_size and trials < i_max :\n",
    "    r = data.append(create_lable_new_examples(data,ensamble_list,r_size))\n",
    "    ensamble_list.append(create_classifier(r))\n",
    "    ensemble_error_r = compute_ensemble_error(data,[ensamble_list[-1]])\n",
    "    if ensemble_error_r < ensemble_error:\n",
    "        i = i + 1\n",
    "        ensemble_error = ensemble_error_r \n",
    "    else:\n",
    "        del ensamble_list[-1]\n",
    "    trials = trials + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates dataframe from csv file. factorizes all object attributes ad leaves numeric attributes\n",
    "def extract_features():\n",
    "    file_names=['Credit Approval'] # will need to be removed\n",
    "    for i in file_names:\n",
    "        file_directory = 'Datasets/'+i+'.csv'\n",
    "        data = pd.read_csv(file_directory)\n",
    "        data = data.replace(['?',' '], np.nan) # replace all empty values to np.nan\n",
    "        data = data.dropna(axis=0,how='any') # remove all rows with any np.nan\n",
    "    for i in data.columns:\n",
    "        if data[i].dtype == object:\n",
    "            data[i] = pd.factorize(data[i])[0]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recieves dataframe and outputs the model - In this case, decision tree\n",
    "def create_classifier(data):\n",
    "    x = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.33,random_state=101)\n",
    "    dtree = DecisionTreeClassifier()\n",
    "    dtree.fit(x_train,y_train)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    return dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recieves data set and list of models. returns the confusion matrix of the majority vote of the ensamble\n",
    "def compute_ensemble_error(data,ensamble_list):\n",
    "    x = data.iloc[:, :-1]\n",
    "    y = data.iloc[:, -1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.33,random_state=101)\n",
    "    #import pdb; pdb.set_trace()\n",
    "    comulative_error = 0 \n",
    "    predictions_list = []\n",
    "    for dtree in ensamble_list: # generate list if all classifiers classifications\n",
    "        predictions_list.append(dtree.predict(x_test))\n",
    "    c_star =pd.DataFrame(pd.DataFrame(predictions_list).T.apply(lambda x: x.value_counts(), axis = 1).idxmax(axis=1))\n",
    "    #import pdb; pdb.set_trace()\n",
    "    ensamble_error = 1 - accuracy_score(y_test,c_star)\n",
    "    return (ensamble_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recieves data frame (DF) and r_size, returns r_size DF of randomly generated values with the structure of the DF\n",
    "def create_training_examples(data,r_size):\n",
    "    mean = data.mean()\n",
    "    std = data.std()\n",
    "    dic = dict()\n",
    "    for i,col in enumerate(data.columns):\n",
    "        dic[col] = np.random.normal(mean[i],std[i],r_size)\n",
    "    d = pd.DataFrame(dic)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recieves dataframe (DF), list of models (ensable) and r_size. Returns DF with r_size new exmples with lables that are opposite\n",
    "# to the majority vote of the ensamle (see idxmin())\n",
    "def create_lable_new_examples(data,ensamble_list,r_size):\n",
    "    r_examples = create_training_examples(data,r_size)\n",
    "    predictions = pd.DataFrame([[0]*r_size,[1]*r_size]).T\n",
    "    #import pdb; pdb.set_trace()\n",
    "    for i,model in enumerate(ensamble_list):\n",
    "        predictions.append(pd.DataFrame(ensamble_list[i].predict(r_examples.iloc[:,:-1])),ignore_index = True)        \n",
    "    predictions = predictions.apply(lambda x: x.value_counts(), axis = 1).idxmin(axis=1)\n",
    "    print(predictions)\n",
    "    r_examples[data.columns[-1]] = predictions\n",
    "\n",
    "    return (r_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
